package processors

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/dbo-studio/dbo/internal/app/dto"
	"github.com/dbo-studio/dbo/internal/database"
	databaseConnection "github.com/dbo-studio/dbo/internal/database/connection"
	"github.com/dbo-studio/dbo/internal/model"
	"github.com/dbo-studio/dbo/internal/repository"
	"github.com/dbo-studio/dbo/internal/service/job"
	"github.com/dbo-studio/dbo/pkg/csv"
	"github.com/dbo-studio/dbo/pkg/helper"
	"github.com/samber/lo"
)

type ExportProcessor struct {
	jobManager     job.IJobManager
	cm             *databaseConnection.ConnectionManager
	connectionRepo repository.IConnectionRepo
}

func NewExportProcessor(jobManager job.IJobManager, cm *databaseConnection.ConnectionManager, connectionRepo repository.IConnectionRepo) *ExportProcessor {
	return &ExportProcessor{
		jobManager:     jobManager,
		cm:             cm,
		connectionRepo: connectionRepo,
	}
}

func (p *ExportProcessor) GetType() model.JobType {
	return model.JobTypeExport
}

func (p *ExportProcessor) Process(job *model.Job) error {
	if job.Status == model.JobStatusCancelled {
		return fmt.Errorf("job was cancelled")
	}

	data, err := helper.ConvertToDTO[dto.ExportRequest]([]byte(job.Data))
	if err != nil {
		return err
	}

	connection, err := p.connectionRepo.Find(context.Background(), data.ConnectionId)
	if err != nil {
		return err
	}

	repo, err := database.NewDatabaseRepository(connection, p.cm)
	if err != nil {
		return err
	}

	err = p.jobManager.UpdateJobProgress(job, 10, "Connected to database")
	if err != nil {
		return err
	}

	err = p.jobManager.UpdateJobProgress(job, 20, "Executing query")
	if err != nil {
		return err
	}

	result, err := repo.RunRawQuery(&dto.RawQueryRequest{
		ConnectionId: int32(connection.ID),
		Query:        data.Query,
	})

	if err != nil {
		return err
	}

	if result == nil {
		return fmt.Errorf("no result found for query %s", data.Query)
	}

	err = p.jobManager.UpdateJobProgress(job, 50, fmt.Sprintf("Found %d rows to export", len(result.Data)))
	if err != nil {
		return fmt.Errorf("failed to update progress: %w", err)
	}

	var filePath string
	var fileName string
	if data.SavePath != "" {
		filePath = data.SavePath
		fileName = filepath.Base(data.SavePath)
		dir := filepath.Dir(data.SavePath)
		if err := os.MkdirAll(dir, 0755); err != nil {
			return fmt.Errorf("failed to create directory: %w", err)
		}
	} else {
		exportDir := "exports"
		if err := os.MkdirAll(exportDir, 0755); err != nil {
			return fmt.Errorf("failed to create export directory: %w", err)
		}
		timestamp := time.Now().Format("20060102_150405")
		fileName = fmt.Sprintf("export_%s_%s.%s", data.Table, timestamp, data.Format)
		filePath = filepath.Join(exportDir, fileName)
	}

	err = p.jobManager.UpdateJobProgress(job, 70, "Creating export file")
	if err != nil {
		return err
	}

	var fileContent []byte
	switch data.Format {
	case "sql":
		fileContent = generateSQLExportFromData(data.Table, result.Columns, result.Data)
	case "json":
		fileContent = generateJsonExport(result.Columns, result.Data)
	case "csv":
		headers := lo.Map(result.Columns, func(col dto.Column, _ int) string { return col.Name })
		fileContent = []byte(csv.Writer(headers, result.Data))
	default:
		return fmt.Errorf("unsupported format: %s", data.Format)
	}

	if err := os.WriteFile(filePath, fileContent, 0644); err != nil {
		return fmt.Errorf("failed to write export file: %w", err)
	}

	fileInfo, err := os.Stat(filePath)
	if err != nil {
		return fmt.Errorf("failed to get file info: %w", err)
	}

	err = p.jobManager.UpdateJobProgress(job, 100, "Export completed successfully")
	if err != nil {
		return fmt.Errorf("failed to update progress: %w", err)
	}

	job.Result = model.JobResult{
		FileName:    fileName,
		FilePath:    filePath,
		Size:        fileInfo.Size(),
		Rows:        len(result.Data),
		Columns:     len(result.Columns),
		TotalChunks: 1,
		ChunkSize:   len(result.Data),
		Query:       data.Query,
	}

	return nil
}

func generateSQLExportFromData(tableName string, columns []dto.Column, data []map[string]any) []byte {
	var sql strings.Builder

	sql.WriteString("-- Export Data\n")
	sql.WriteString("-- Generated by DBO Studio\n")
	sql.WriteString("-- Generated on: " + time.Now().Format("2006-01-02 15:04:05") + "\n\n")

	if len(data) > 0 {
		sql.WriteString(fmt.Sprintf("INSERT INTO %s (", tableName))
		for i, col := range columns {
			sql.WriteString(col.Name)
			if i < len(columns)-1 {
				sql.WriteString(", ")
			}
		}
		sql.WriteString(") VALUES\n")

		for i, row := range data {
			sql.WriteString("(")
			for j, col := range columns {
				value := row[col.Name]

				if value == nil {
					sql.WriteString("NULL")
				} else {
					sql.WriteString(helper.FormatSQLValue(value))
				}

				if j < len(columns)-1 {
					sql.WriteString(", ")
				}
			}
			sql.WriteString(")")
			if i < len(data)-1 {
				sql.WriteString(",\n")
			} else {
				sql.WriteString(";\n")
			}
		}
	}

	return []byte(sql.String())
}

func generateJsonExport(columns []dto.Column, rows []map[string]any) []byte {
	jsonData := make([]map[string]any, len(rows))
	for i, row := range rows {
		jsonData[i] = make(map[string]any)
		for _, col := range columns {
			jsonData[i][col.Name] = row[col.Name]
		}
	}
	return []byte(helper.StructToJson(jsonData))
}
